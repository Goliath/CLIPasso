{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CLIPSketch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOOQ1K3G9T5n2Bo4bDy1zFQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yael-vinker/CLIPSketch/blob/main/CLIPSketch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *CLIPSketch* - sketch your own image"
      ],
      "metadata": {
        "id": "Ht4wCUlzwi18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies and Clone the Repo\n",
        "\n",
        "Make sure your Hardware accelerator is set to GPU.\n",
        " \n",
        "Runtime > Change runtime type > Hardware Accelerator "
      ],
      "metadata": {
        "id": "1V-3h8-awFYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/yael-vinker/CLIPSketch.git\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "user = getpass('GitHub user')\n",
        "password = getpass('GitHub password')\n",
        "os.environ['GITHUB_AUTH'] = user + ':' + password\n",
        "\n",
        "!git clone https://$GITHUB_AUTH@github.com/yael-vinker/CLIPSketch.git\n",
        "%cd CLIPSketch\n",
        "!pip install -r requirements.txt\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!git clone https://github.com/BachiLi/diffvg\n",
        "%cd diffvg\n",
        "!git submodule update --init --recursive\n",
        "!python setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0mW2URSK_Nd",
        "outputId": "0bfc8aae-978f-483e-e474-2f550a2475cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GitHub user··········\n",
            "GitHub password··········\n",
            "fatal: destination path 'CLIPSketch' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sketch your own "
      ],
      "metadata": {
        "id": "L7Cp8FFHx3VG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CLIPSketch\n",
        "\n",
        "import subprocess as sp\n",
        "import numpy as np\n",
        "import os\n",
        "import multiprocessing as mp\n",
        "import warnings\n",
        "import pydiffvg\n",
        "import torch\n",
        "import traceback\n",
        "import logging\n",
        "\n",
        "from torch.nn.parallel import parallel_apply\n",
        "from shutil import copyfile\n",
        "from PIL import Image\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')\n",
        "warnings.filterwarnings(action='once')\n",
        "\n",
        "manager = mp.Manager()\n",
        "exit_codes = []\n",
        "losses_all = manager.dict()\n",
        "\n",
        "if not os.path.isfile(\"/content/CLIPSketch/U2Net_/saved_models/u2net.pth\"):\n",
        "    sp.run([\"gdown\", \"https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ\", \"-O\", \"U2Net_/saved_models/\"])\n",
        "\n",
        "test_name = \"my_targets\"\n",
        "output_dir = f\"/content/CLIPSketch/output_sketches/{test_name}/\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgNpuzBBTSVa",
        "outputId": "5ddcc5e1-fdf0-4cb4-82fe-a1c74759c8b4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CLIPSketch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CLIPSketch/\n",
        "\n",
        "target_image = \"camel.png\" #@param {\"type\": \"string\"}\n",
        "target_name = \"camel\" #@param {\"type\": \"string\"}\n",
        "\n",
        "targets = [f\"/content/CLIPSketch/target_images/{target_image}\"]\n",
        "target_names = [f\"{target_name}\"]\n",
        "num_iter = 20\n",
        "save_interval = 5\n",
        "use_gpu=1\n",
        "seeds = [100]\n",
        "\n",
        "# if you need to mask the input image and pad the aspect ratio\n",
        "fix_scale=0\n",
        "mask_object=0\n",
        "mask_object_attention=0\n",
        "\n",
        "def run(target, seed, wandb_name):\n",
        "    proc = sp.Popen([\"python\", \"-W\",\"ignore\", \"painterly_rendering.py\", target, \n",
        "                                \"--output_dir\", output_dir,\n",
        "                                \"--wandb_name\", wandb_name,\n",
        "                                \"--num_iter\", str(num_iter),\n",
        "                                \"--save_interval\", str(save_interval),\n",
        "                                \"--seed\", str(seed),\n",
        "                                \"--use_gpu\", str(use_gpu),\n",
        "                                \"--fix_scale\", str(fix_scale), \n",
        "                                \"--mask_object\", str(mask_object),\n",
        "                                \"--mask_object_attention\", str(mask_object_attention)])\n",
        "    try:\n",
        "      outs, errs = proc.communicate(timeout=20000)\n",
        "    except Exception as e:\n",
        "      logging.error(traceback.format_exc())\n",
        "    config = np.load(f\"{output_dir}/{wandb_name}/config.npy\", allow_pickle=True)[()]\n",
        "    loss_eval = np.array(config['loss_eval'])\n",
        "    inds = np.argsort(loss_eval)\n",
        "    losses_all[wandb_name] = loss_eval[inds][0]\n",
        "\n",
        "ncpus=10\n",
        "P = mp.Pool(ncpus) # Generate pool of workers\n",
        "for target, target_name in zip(targets, target_names): # Generate processes\n",
        "    for seed in seeds:\n",
        "        wandb_name=f\"{target_name}_seed{seed}\"\n",
        "        P.apply_async(run,(target, seed, wandb_name)) # run simulation and ISF analysis in each process\n",
        "        # run(target, seed, wandb_name)\n",
        "\n",
        "    P.close()\n",
        "    P.join() # start processes \n",
        "\n",
        "    sorted_final = dict(sorted(losses_all.items(), key=lambda item: item[1]))\n",
        "    copyfile(f\"{output_dir}/{list(sorted_final.keys())[0]}/best_iter.svg\", f\"{output_dir}/{list(sorted_final.keys())[0]}_best.svg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm7LBVl7U4Vh",
        "outputId": "6cb69e9a-ca9a-43b1-d3d3-b89e107518db"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CLIPSketch\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "[W accumulate_grad.h:170] Warning: grad and param do not obey the gradient layout contract. This is not an error, but may impair performance.\n",
            "grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1]\n",
            "param.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512] (function operator())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results will be saved to /content/CLIPSketch/output_sketches/camel/camel_seed100\n",
            "cuda\n",
            "====================================================================================================\n",
            "test epoch[0/20] loss[0.317962646484375] time[0.355724573135376]\n",
            "====================================================================================================\n",
            "====================================================================================================\n",
            "test epoch[10/20] loss[0.30072021484375] time[0.26178407669067383]\n",
            "====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gifs for video\n",
        "import imageio\n",
        "import moviepy.editor as mvp\n",
        "from subprocess import call\n",
        "import os\n",
        "\n",
        "def read_svg(path_svg, multiply=False):\n",
        "    canvas_width, canvas_height, shapes, shape_groups = pydiffvg.svg_to_scene(path_svg)\n",
        "    if multiply:\n",
        "        canvas_width *= 2\n",
        "        canvas_height *= 2\n",
        "        for path in shapes:\n",
        "            path.points *= 2\n",
        "            path.stroke_width *= 2\n",
        "    _render = pydiffvg.RenderFunction.apply\n",
        "    scene_args = pydiffvg.RenderFunction.serialize_scene(canvas_width, canvas_height, shapes, shape_groups)\n",
        "    img = _render(canvas_width, # width\n",
        "                canvas_height, # height\n",
        "                2,   # num_samples_x\n",
        "                2,   # num_samples_y\n",
        "                0,   # seed\n",
        "                None,\n",
        "                *scene_args)\n",
        "    img = img[:, :, 3:4] * img[:, :, :3] + torch.ones(img.shape[0], img.shape[1], 3, device = device) * (1 - img[:, :, 3:4])\n",
        "    img = img[:, :, :3]\n",
        "    return img\n",
        "\n",
        "path_res = f\"{output_dir}\"\n",
        "for target in targets:\n",
        "    for seed in seeds:\n",
        "        sketches = []\n",
        "        wandb_name=f\"{target_name}_seed{seed}\"\n",
        "        cur_path = f\"{path_res}/{wandb_name}\"\n",
        "        if os.path.exists(f\"{cur_path}/config.npy\"):\n",
        "            config = np.load(f\"{cur_path}/config.npy\", allow_pickle=True)[()]\n",
        "            inter = config[\"save_interval\"]\n",
        "            loss_eval = np.array(config['loss_eval'])\n",
        "            inds = np.argsort(loss_eval)\n",
        "            intervals = list(range(0, (inds[0] + 1) * inter,inter))\n",
        "            for i_ in intervals:\n",
        "                path_svg = f\"{cur_path}/svg_iter{i_}.svg\"\n",
        "                sketch = read_svg(path_svg, multiply=True).cpu().numpy()\n",
        "                sketch = Image.fromarray((sketch * 255).astype('uint8'), 'RGB')\n",
        "                print(\"{0}/iter_{1:04}.png\".format(cur_path, int(i_)))\n",
        "                sketch.save(\"{0}/iter_{1:04}.png\".format(cur_path, int(i_)))\n",
        "                sketches.append(sketch)\n",
        "            imageio.mimsave(f\"{cur_path}/sketch.gif\", sketches)\n",
        "\n",
        "            call([\"ffmpeg\", \"-y\", \"-framerate\", \"10\", \"-pattern_type\", \"glob\", \"-i\", \n",
        "                  f\"{cur_path}/iter_*.png\", \"-vb\", \"20M\",\n",
        "                f\"{cur_path}/sketch.mp4\"])\n",
        "\n",
        "\n",
        "            call([\"ffmpeg\", \"-y\", \"-i\", f\"{cur_path}/sketch.mp4\", \"-filter_complex\",\n",
        "                \"[0]trim=0:2[hold];[0][hold]concat[extended];[extended][0]overlay\",\n",
        "                f\"{cur_path}/sketch_longer.mp4\"])\n",
        "\n",
        "\n",
        "    display(mvp.ipython_display(f\"{cur_path}/sketch_longer.mp4\"))\n",
        "#     display(mvp.ipython_display(f\"{cur_path}/out.mp4\"))\n"
      ],
      "metadata": {
        "id": "kCqAxSN9ymqj",
        "outputId": "fa27e192-240e-441d-b72f-61b6e4d9e88c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CLIPSketch/output_sketches/camel//camel_seed100/iter_0000.png\n",
            "/content/CLIPSketch/output_sketches/camel//camel_seed100/iter_0010.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2, from '/content/CLIPSketch/output_sketches/camel//camel_seed100/iter_*.png':\n",
            "  Duration: 00:00:00.20, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 448x448, 10 tbr, 10 tbn, 10 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "[libx264 @ 0x55f2a454be00] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "[libx264 @ 0x55f2a454be00] profile High 4:4:4 Predictive, level 3.0, 4:4:4 8-bit\n",
            "[libx264 @ 0x55f2a454be00] 264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x1:0x111 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=0 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=10 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=abr mbtree=1 bitrate=20000 ratetol=1.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/CLIPSketch/output_sketches/camel//camel_seed100/sketch.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv444p, 448x448, q=-1--1, 20000 kb/s, 10 fps, 10240 tbn, 10 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/20000000 buffer size: 0 vbv_delay: -1\n",
            "frame=    2 fps=0.0 q=-1.0 Lsize=      10kB time=00:00:00.10 bitrate= 814.6kbits/s speed=2.32x    \n",
            "video:9kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 8.806576%\n",
            "[libx264 @ 0x55f2a454be00] frame I:1     Avg QP: 0.29  size:  3957\n",
            "[libx264 @ 0x55f2a454be00] frame P:1     Avg QP: 3.59  size:  4706\n",
            "[libx264 @ 0x55f2a454be00] mb I  I16..4: 94.0%  0.0%  6.0%\n",
            "[libx264 @ 0x55f2a454be00] mb P  I16..4:  1.3%  0.0%  5.7%  P16..4:  0.4%  0.6%  0.3%  0.0%  0.0%    skip:91.7%\n",
            "[libx264 @ 0x55f2a454be00] final ratefactor: -20.72\n",
            "[libx264 @ 0x55f2a454be00] coded y,u,v intra: 6.0% 0.0% 0.0% inter: 0.5% 0.0% 0.0%\n",
            "[libx264 @ 0x55f2a454be00] i16 v,h,dc,p: 95%  1%  4%  0%\n",
            "[libx264 @ 0x55f2a454be00] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 18% 15% 44%  3%  4%  4%  5%  4%  3%\n",
            "[libx264 @ 0x55f2a454be00] Weighted P-Frames: Y:0.0% UV:0.0%\n",
            "[libx264 @ 0x55f2a454be00] kb/s:346.52\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/CLIPSketch/output_sketches/camel//camel_seed100/sketch.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "  Duration: 00:00:00.20, start: 0.000000, bitrate: 407 kb/s\n",
            "    Stream #0:0(und): Video: h264 (High 4:4:4 Predictive) (avc1 / 0x31637661), yuv444p, 448x448, 374 kb/s, 10 fps, 10 tbr, 10240 tbn, 20 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "Stream mapping:\n",
            "  Stream #0:0 (h264) -> trim\n",
            "  Stream #0:0 (h264) -> concat:in0:v0\n",
            "  Stream #0:0 (h264) -> overlay:overlay\n",
            "  overlay -> Stream #0:0 (libx264)\n",
            "Press [q] to stop, [?] for help\n",
            "[libx264 @ 0x556268935900] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "[libx264 @ 0x556268935900] profile High, level 2.1\n",
            "[libx264 @ 0x556268935900] 264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=10 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/CLIPSketch/output_sketches/camel//camel_seed100/sketch_longer.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 448x448, q=-1--1, 10 fps, 10240 tbn, 10 tbc (default)\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1652\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1610\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_4447/194496198.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m             call([\"ffmpeg\", \"-y\", \"-i\", f\"{cur_path}/sketch.mp4\", \"-filter_complex\",\n\u001b[1;32m     57\u001b[0m                 \u001b[0;34m\"[0]trim=0:2[hold];[0][hold]concat[extended];[extended][0]overlay\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 f\"{cur_path}/sketch_longer.mp4\"])\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Including KeyboardInterrupt, wait handled that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sigint_wait_secs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# nothing else should wait.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigint_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1645\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutExpired\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m                     \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/CLIPSketch/\n",
        "!python general_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtiEiTO8Z_9B",
        "outputId": "190eef9e-6ca7-4b44-b548-e393d07af732"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CLIPSketch\n",
            "in main\n",
            "results will be saved to output_sketches/camel/camel_seed0\n",
            "cuda\n",
            "{'target': 'target_images/camel.png', 'output_dir': 'output_sketches/camel/camel_seed0', 'path_svg': 'none', 'use_gpu': 1, 'seed': 0, 'mask_object': 0, 'fix_scale': 0, 'use_wandb': 0, 'wandb_user': 'yael-vinker', 'wandb_name': 'camel_seed0', 'wandb_project_name': 'none', 'num_iter': 2, 'num_stages': 1, 'lr_scheduler': 0, 'lr': 1.0, 'color_lr': 0.01, 'color_vars_threshold': 0.0, 'batch_size': 1, 'save_interval': 1, 'eval_interval': 10, 'image_scale': 224, 'num_paths': 16, 'width': 1.5, 'control_points_per_seg': 4, 'num_segments': 1, 'attention_init': 1, 'saliency_model': 'clip', 'saliency_clip_model': 'ViT-B/32', 'xdog_intersec': 1, 'mask_object_attention': 0, 'softmax_temp': 0.3, 'percep_loss': 'none', 'perceptual_weight': 0, 'train_with_clip': 0, 'clip_weight': 0, 'start_clip': 0, 'num_aug_clip': 4, 'include_target_in_aug': 0, 'augment_both': 1, 'augemntations': 'affine', 'noise_thresh': 0.5, 'aug_scale_min': 0.7, 'force_sparse': 0, 'clip_conv_loss': 1, 'clip_conv_loss_type': 'L2', 'clip_conv_layer_weights': [0.0, 0.0, 1.0, 1.0, 0.0], 'clip_model_name': 'RN101', 'clip_fc_loss_weight': 0.1, 'clip_text_guide': 0, 'text_target': 'none', 'device': device(type='cuda')}\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2952: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3063: UserWarning: Default upsampling behavior when mode=bicubic is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional_tensor.py:876: UserWarning: Argument fill/fillcolor is not supported for Tensor input. Fill value is zero\n",
            "  warnings.warn(\"Argument fill/fillcolor is not supported for Tensor input. Fill value is zero\")\n",
            "====================================================================================================\n",
            "test epoch[0/2] loss[0.29486083984375] time[0.35517334938049316]\n",
            "====================================================================================================\n",
            "[W accumulate_grad.h:170] Warning: grad and param do not obey the gradient layout contract. This is not an error, but may impair performance.\n",
            "grad.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 1, 1]\n",
            "param.sizes() = [2048, 512, 1, 1], strides() = [512, 1, 512, 512] (function operator())\n",
            "==================\n",
            "multi process 26.934223413467407\n"
          ]
        }
      ]
    }
  ]
}